{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community -q\n",
        "!pip install pypdf -q\n",
        "!pip install tiktoken -q\n",
        "!pip install langchain -q\n",
        "!pip install langchain-text-splitters -q\n",
        "!pip install langchain_google_genai -q\n",
        "!pip install langchain_pinecone -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-Hzrhk3fkuC",
        "outputId": "b9b34261-f1a0-454b-9506-6b3f4652bcd0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.2 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/MachineTranslationwithAttention.pdf\""
      ],
      "metadata": {
        "id": "hTkWOwZqfwBB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"/content/MachineTranslationwithAttention.pdf\")"
      ],
      "metadata": {
        "id": "fjgQ1UrId5Rn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "text_spliter = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50)"
      ],
      "metadata": {
        "id": "ORhOCvTlf97p"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = loader.load_and_split(text_spliter)"
      ],
      "metadata": {
        "id": "qctbsSMxg0uo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeTVb0tQlAgn",
        "outputId": "62a02ead-223e-4150-c262-8b0a80b59b0d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "\n",
        "PINECONE_API_KEY = userdata.get('PINECONE_API')\n",
        "os.environ[\"PINECONE_APIKEY\"] = PINECONE_API_KEY"
      ],
      "metadata": {
        "id": "-oFYd7CFlC2s"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(GOOGLE_API_KEY)\n",
        "print(PINECONE_API_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7fBQDsnoCFu",
        "outputId": "1f04e8f8-9608-48ca-e3c3-a0fdf6ae09ba"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AIzaSyARxm0Lk5SXSHRMt_Rw3iklQrVQcGRgVCA\n",
            "b0751b74-46c4-4cd5-ae4e-cf99ae28d260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
        "embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkMsSfLRlEwU",
        "outputId": "ccc92d63-4d1e-4c47-ae50-da82ae5ae461"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogleGenerativeAIEmbeddings(client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x78baee5535e0>, model='models/text-embedding-004', task_type=None, google_api_key=SecretStr('**********'), credentials=None, client_options=None, transport=None, request_options=None)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectors=embeddings.embed_query(\"How are you?\")\n",
        "len(vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YknPajmTmBlA",
        "outputId": "4f787f40-2f6a-42ad-a5f2-5894bb8c37f1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "index_name = 'qabot'\n",
        "vectorstore = PineconeVectorStore(pinecone_api_key=PINECONE_API_KEY, index_name=index_name, embedding=embeddings)"
      ],
      "metadata": {
        "id": "03DKKUc6mxu2"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.add_documents(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN6p9E74ntEz",
        "outputId": "1649fd32-2d2e-4163-c609-948a1d466348"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['022a5efe-2642-415a-88a2-0582c5352d63',\n",
              " 'd5900d2e-107a-49d3-b7bd-393bbe5afb63',\n",
              " '06f02a3e-4ca2-407d-93ff-b969c014e5f7',\n",
              " 'f3d2cd06-8dcb-46c0-a67e-38e73aab8748',\n",
              " '97aabde6-390f-4af1-ae1f-e6b0eb6011dd',\n",
              " 'bcdff59a-2e2d-4687-a713-38a442bb21f3',\n",
              " 'c20036ff-e4cb-42cd-b00d-6e7056f11ea3',\n",
              " '3154df96-4f0b-4862-b0b8-4fd9e61847b5',\n",
              " '00c92a80-eecb-44b8-b145-38f63e3b450c',\n",
              " '2a0dfd88-ee94-4abc-b59c-48374da60776',\n",
              " '6438c961-f019-4727-8d33-a0b77d267196',\n",
              " '66bef94e-8f8b-498a-a135-eb51c9892685',\n",
              " '7a116ee8-96f3-4a77-a88f-c134a50738ee',\n",
              " '7bd246a3-af55-483c-bdd0-a8b11d56c3ab',\n",
              " '93f53be2-0103-497d-bf51-55e747b5dcb9',\n",
              " 'b4de0e95-bbd6-4236-a815-9efc4a36e746',\n",
              " '1b2ea993-6836-49da-a505-f480ceafe076',\n",
              " '813d19df-17b2-4e08-a588-0e0c26479ea4',\n",
              " 'a582c2e3-74d2-4111-8153-bb96f114e5de',\n",
              " '814654b3-beb3-402c-87f6-498e74ecb7cd',\n",
              " 'c777ce7d-5245-4bc2-9617-18f32836938b',\n",
              " '8dab0820-4942-4983-adb7-c001de4f8acf',\n",
              " '57490cc4-293d-41f1-b863-0c27ecba3d28',\n",
              " 'ae28cf69-6b4b-4ac4-9db5-c48cdacffbd3',\n",
              " '0c37700f-8be8-431f-a3f1-e7f44bdfe8ff',\n",
              " 'b1c959a1-5715-4bfb-84a9-be869c0ad454',\n",
              " '627f5253-835c-4362-b946-cee74a2f32fd',\n",
              " '2a2f6eb5-88ad-4115-9a39-e2d93d1d44f0',\n",
              " 'cf3ffaed-892d-4a81-9d49-0897d98d495d',\n",
              " 'a6760d9e-4134-4ad9-9202-39439faa3e32',\n",
              " '8af71232-bdd5-40dd-ad2c-64d9d1e71d01',\n",
              " 'eb1bfe13-80b0-4b96-9d1d-c42bb910a936',\n",
              " '40defbea-1dee-44dd-a45e-fdad19b3c072',\n",
              " '0450bf06-99fa-4922-9096-d1685fce5d76',\n",
              " '8332e6ab-13d9-4866-9398-8b2c0f643378',\n",
              " '5559ed3c-e52e-4a98-8ee5-5e0c042d3009',\n",
              " '1f82984b-8246-42b0-87ae-061eee022f18',\n",
              " '0d18f75c-4916-4d7b-adab-7914056dea22',\n",
              " '43b12604-678a-4a74-8b82-e133d16639c0',\n",
              " 'a0f4867d-d22d-448b-8eed-233be98862b8',\n",
              " 'd56f011b-60ad-4f44-a520-36096667507e',\n",
              " '0db7c280-2944-4cb7-944f-970a1d8bff32',\n",
              " '2359c19e-d9df-4d63-bdf5-1ff94e8876d2',\n",
              " 'e6574109-c07e-40ec-b2f9-5e2d871e2a7c',\n",
              " 'e5ebf680-68ef-4278-a2ac-272d17f5ab76',\n",
              " 'fe8a0fef-88f3-4616-8d7d-18b69d0f1755',\n",
              " '6349b978-22a5-4f45-a777-e63abe0bfa17',\n",
              " 'e25780df-51d6-41ad-a632-7c3490c1fc44',\n",
              " 'd2cf6a36-2788-47f4-abb6-e98072023ed5',\n",
              " 'cc6f55f2-a37a-4f40-9229-cfe154a49274',\n",
              " '7107a615-39b8-4754-a597-972f1677e2a0',\n",
              " '221d5f5a-9c70-4548-b9ba-d975e738008b',\n",
              " 'd40b7093-f2d5-453a-bb85-371d63962194',\n",
              " 'da14abb3-3885-4e15-bfa1-99765791ce4b',\n",
              " '083520ce-5ca7-4128-b38b-0a020595abba',\n",
              " '8f0a9c0b-3009-4f76-ad9e-d42511e53601',\n",
              " 'da385dc4-b33d-4323-8368-35fa3ff578ce',\n",
              " 'd8f13cd2-de54-4f2a-8483-175b0548ba32',\n",
              " '86e69fcc-5d28-4584-a4b9-50440f17d895',\n",
              " 'c6091de0-2802-423a-829d-cc1b73e3dee0',\n",
              " 'edcdc190-d99f-420c-b69b-fc1b99b46e57',\n",
              " '0b84ae1b-6169-4c6a-bfbc-ca8172b7e925',\n",
              " '0c6516f2-b92b-4ddf-9c6c-944684401191',\n",
              " '235888eb-9656-4840-8c07-a98be9a8e177',\n",
              " '5a8b8f57-b5fa-4359-8d86-b065fd601599',\n",
              " 'c78d76e4-68e9-4ce9-b3ee-48dc61756bbb',\n",
              " '660a06f0-85dd-4814-9345-9b954d7d50e4',\n",
              " '0bbd9740-97c4-40c7-9250-2106f43e696a',\n",
              " '10bf5c7d-6a21-4c84-a1da-d63f05344ec2',\n",
              " 'a6be6491-0a4f-49a4-bc31-48ec4866107c',\n",
              " 'f356c434-1f26-49be-baaf-dedc9c31d37d',\n",
              " '2b65e3e4-6d80-40ba-9e8b-37ab11e0fe7c',\n",
              " '655476d4-f16c-4da9-9a09-5ff9b9f7408a',\n",
              " 'e5be7500-bd04-4d39-b413-aadf02d02a93',\n",
              " '49b5623f-3892-46e3-a8db-30239278ba49',\n",
              " '6e3b68fc-7be0-4f44-a5db-667d4ab8fb4f',\n",
              " '4bd46642-ca11-4500-9d16-0914619b60fa',\n",
              " 'a75f3a60-3b23-465f-90e7-e097ae1a7a3b',\n",
              " '8388ffb3-7d99-4c4f-bfa1-15bb8804e4d5',\n",
              " 'f2c0629c-7f17-4735-b1f2-3199a92b27fc']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is attention?\"\n",
        "vectorstore.similarity_search(\n",
        "    query,  # our search query\n",
        "    k=3  # return 3 most relevant docs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfy1gkDrorrV",
        "outputId": "1891af9b-9730-447e-f6ae-a5f640cc346e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='5559ed3c-e52e-4a98-8ee5-5e0c042d3009', metadata={'page': 4.0, 'source': '/content/MachineTranslationwithAttention.pdf'}, page_content='The ﬁrst attention model was proposed by Bah-\\ndanau et al. (2014), there are several other types of\\nattention proposed, such as the one by Luong et al.'),\n",
              " Document(id='8332e6ab-13d9-4866-9398-8b2c0f643378', metadata={'page': 4.0, 'source': '/content/MachineTranslationwithAttention.pdf'}, page_content='decoding phase.\\nDuring the decoding phase, the model creates\\nan alignment between each time step of the de-\\ncoder output and all of the encoder hidden state.\\nWe need to learn this alignment. Each output of\\nthe decoder can selectively pick out speciﬁc ele-\\nments from the sequence to produce the output.\\nSo, this allows the model to focus and pay more\\n”Attention” to the relevant part of the input se-\\nquence.\\nThe ﬁrst attention model was proposed by Bah-'),\n",
              " Document(id='d56f011b-60ad-4f44-a520-36096667507e', metadata={'page': 5.0, 'source': '/content/MachineTranslationwithAttention.pdf'}, page_content='concentrate on few relevant parts of the sequence\\nwhen predicting the next word.\\nAfter calculating the alignment score, we pass\\nthe vectoretthrough the softmax layer, to calcu-\\nlate the probability distribution.\\nαt=softmax (et)\\nThen we multiply each of the attention weights\\nwith each of the encoder hidden state, to get con-\\ntext vector,at\\nat=Tx∑\\ni=1αt\\nihi\\nIf the attention score of speciﬁc element of the\\ninput sequence is close to 1, then its inﬂuence on')]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "p6ZhUB-Vo-52"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# RAG prompt\n",
        "template = \"\"\"Answer the question as detailed as possible from the provided context, mae sure to provide all the details, if the answer is not in\n",
        "    the provided context just say, \"answer is not available in the context\", don't provide the wrong answer\\n\\n\n",
        "{context}\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.01)\n",
        "retriever=vectorstore.as_retriever()\n",
        "\n",
        "chain = (\n",
        "    RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "Pvt3GegkpRyO"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Quantitative Result?\""
      ],
      "metadata": {
        "id": "EtE1fkbFqVze"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gdjrfgI0p21w",
        "outputId": "5fa1e72d-abe5-4da9-e0f7-89a7cb7dccdf"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The quantitative result is the BLEU score used to evaluate the model's performance on the test data. The model was trained on sentences with a maximum length of 50. \\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query1 = \"What is attention?\"\n",
        "chain.invoke(query1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "zZqwyWmcqONK",
        "outputId": "e5ba0daf-1524-4f97-80c5-57fc97a7bce6"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Attention is a mechanism that allows a model to focus on specific parts of the input sequence when making predictions. It helps the model to selectively pick out relevant elements from the sequence to produce the output. This allows the model to pay more attention to the relevant parts of the input sequence. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query2 = \"What is Encoder and Decoder?\"\n",
        "chain.invoke(query2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "5TehdcPuqusm",
        "outputId": "65b06638-4c98-40cf-e121-888a48b712e5"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Encoder-Decoder, first proposed by Cho et al. (2014b), basically consists of 2 parts, the encoder and the decoder. Encoder codes the sequence of input sentence into dense vector representation, and then decoder takes in the encoded sentence and decode the representation into another sequences of words. They are trained to maximize the conditional probability of the output sentence, given the input sentence. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lFmQjVHnq1b8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}